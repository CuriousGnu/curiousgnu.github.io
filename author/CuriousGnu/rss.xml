<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>www.curiousgnu.com</title>
   
   <link>https://www.curiousgnu.com/</link>
   <description>Numbers, Graphs, and Apple Strudels</description>
   <language>en-uk</language>
   <managingEditor> CuriousGnu</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Analyzing Subtitles - Chick Flick or Guy Movie?</title>
	  <link>//subtitles-target-audience</link>
	  <author>CuriousGnu</author>
	  <pubDate>2017-03-22T03:00:00+01:00</pubDate>
	  <guid>//subtitles-target-audience</guid>
	  <description><![CDATA[
	     <p>Romantic comedy or action movie? While this cliché certainly oversimplifies the differences in movie preferences between men and women, it is common knowledge that certain movie genres primarily target one gender. The colloquial term <em>chick flick</em> refers to movies targeted to a female audience whereas <em>guy movies</em> are mainly aimed at male viewers. For example, a study found that female viewers have a stronger preference for movies with happier themes than their male counterparts (<cite><a href="http://dx.doi.org/10.1027/1864-1105.20.3.97">Banerjee et al., 2008</a></cite>).</p>

<p>For this post, my goal is to investigate how <em>chick flicks</em>, and <em>guy movies</em> differ regarding the words spoken. As obtaining the original scripts is rather difficult, I decided to analyze the movies’ subtitles instead, which were available from <cite><a href="https://www.amazon.com/s/?rh=n%3A7589478011%2Cn%3A2858905011%2Cp_n_consumption_type%3A9052272011%2Cp_n_feature_fourteen_browse-bin%3A2654454011%2Cp_n_ways_to_watch%3A12007867011%2Cp_n_feature_twelve_browse-bin%3A5824772011">Amazon Video</a></cite>. At the end of this post, you will find a brief description of how subtitles can be downloaded from the Amazon website. Since subtitles are protected by copyright, please understand that I cannot share the files that I used in this project.</p>

<h4 id="data">Data</h4>
<p>I downloaded the subtitles of the <strong>top 1,000</strong> <cite><a href="https://www.amazon.com/s/?rh=n%3A7589478011%2Cn%3A2858905011%2Cp_n_consumption_type%3A9052272011%2Cp_n_feature_fourteen_browse-bin%3A2654454011%2Cp_n_ways_to_watch%3A12007867011%2Cp_n_feature_twelve_browse-bin%3A5824772011">Amazon Video bestsellers</a></cite> (7th March, 2017) and gathered additional information from <cite><a href="https://www.imdb.com">IMDb</a></cite>. To determine whether a film is targeted at a male or female audience, I used the proportion of women votes on the IMDb score. In this sample, women make up on average about <strong>one-quarter</strong> of all gender votes.</p>

<p>25% of the movies with the lowest share of female votes were defined as <em>guy movies</em> while the top 25% were defined as <em>chick flicks</em>. Next, I removed movies with less than 1,000 total votes to ensure a fair comparison. Considering the rather vague definition of these two terms, I believe that this approach is sufficient for this context. The following table shows the top ten movies for each category:</p>

<table style="font-size:14px">
  <thead>
    <tr>
      <th>#</th>
      <th>Guy Movies (% female votes)</th>
      <th>Chick Flicks (% female votes)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Never Back Down: No Surrender (3.8%)</td>
      <td>Northanger Abbey (81.7%)</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Justice League Dark (4.8%)</td>
      <td>Persuasion (72.3%)</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Dragon Ball Z: Resurrection (5.1%)</td>
      <td>The Last Song (65.4%)</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Batman: Bad Blood (5.2%)</td>
      <td>The Princess Diaries 2 (64.1%)</td>
    </tr>
    <tr>
      <td>5</td>
      <td>Justice League: Throne of Atlantis (5.6%)</td>
      <td>Something Borrowed (62.6%)</td>
    </tr>
    <tr>
      <td>6</td>
      <td>Kill Command (5.7%)</td>
      <td>Letters To Juliet (62.5%)</td>
    </tr>
    <tr>
      <td>7</td>
      <td>Justice League vs. Teen Titans (6.3%)</td>
      <td>Ever After: A Cinderella Story (60.7%)</td>
    </tr>
    <tr>
      <td>8</td>
      <td>Headshot (6.4%)</td>
      <td>Little Women (59.7%)</td>
    </tr>
    <tr>
      <td>9</td>
      <td>We Were Soldiers (6.6%)</td>
      <td>27 Dresses (58.5%)</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Predator (6.7%)</td>
      <td>The Young Victoria (58.2%)</td>
    </tr>
  </tbody>
</table>

<h4 id="analysis">Analysis</h4>
<p>First, I used the ‘<cite><a href="https://cran.r-project.org/web/packages/wordcloud/"><em>wordcloud</em></a></cite>’ package in R to plot a comparison word cloud, which highlights the words that were heavily used in one of the two categories. To remove movie specific words, such as character names, I dropped all words from the sample that were not in at least three different movie subtitles.</p>

<p><a href="/assets/images/subtitles-target-audience/wordcloud.png"><img src="/assets/images/subtitles-target-audience/wordcloud.png" alt="Subtitles Wordcloud" style="max-width: 600px" /></a></p>

<p>The more frequent use of profane language in <em>guy movies</em> and the higher use of positive words in <em>chick flicks</em> is in line with the assumption that women prefer relationship movies while men are more interested in thriller and action genres. A quick sentiment analysis performed through the ‘<cite><a href="https://cran.r-project.org/web/packages/sentimentr/"><em>sentimentr</em></a></cite>’ R-package confirms that movies targeted at a female audience are slightly more positive than movies produced for a male audience.</p>

<p><a href="/assets/images/subtitles-target-audience/sentiment.png"><img src="/assets/images/subtitles-target-audience/sentiment.png" alt="Subtitles Sentiment" style="max-width: 500px" /></a></p>

<p>These results show that the use of certain words differs significantly between the two categories. Furthermore, these findings suggest that we can use subtitles to determine whether a movie is more likely to target a male or female audience. As this is a traditional text classification problem, a wide variety of machine learning algorithms exist, such as <cite><a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machines</a></cite>, <cite><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes classifiers</a></cite>, or <cite><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)">boosting classifiers</a></cite>, which could be applied.</p>

<p>Even though some of these algorithms would probably be more accurate and robust for this task, I used a <cite><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">classification tree</a></cite> model (‘<cite><a href="https://cran.r-project.org/web/packages/rpart/index.html"><em>rpart</em></a></cite>’, R-package) because it produces results that are easy to understand and apply. The goal of this method is to derive a set of rules from input variables that can predict which class an item belongs to. In this case, the input variables for each movie are the numbers of occurrences of each word stem. The target category is either <em>chick flick</em> or <em>guy movie</em>. The following tree is based on a randomly selected training set.</p>

<p><a href="/assets/images/subtitles-target-audience/tree.png"><img src="/assets/images/subtitles-target-audience/tree.png" alt="Subtitles Regression Tree" style="max-width: 500px" /></a></p>

<p>According to this model, if the word stem ‘<strong><em>love</em></strong>’ appears more than 11 times in the subtitles and ‘<strong><em>gun</em></strong>’ is only used once, the movie is most likely targeted at women. However, if ‘<strong><em>love</em></strong>’ occurs no more than 11 times in the subtitles and ‘<strong><em>hell</em></strong>’ at least once, the movie is probably produced for a male audience. When applied to the test set, this model predicts <strong>82%</strong> of the categories correctly. This is significantly higher than the <strong>54%</strong> no information rate, which is the percentage of the largest class in the training set.</p>

<p>Overall, I think it is quite interesting to see how the results support the assumption about typical <em>chick flicks</em> and <em>guy movies</em>. Knowing that gender specific movies are a controversial topic for some people, I hope that no one is offended by this post or my choice of words as this is unintentional.</p>

<h5 id="download-subtitles-from-amazon-video">Download Subtitles from Amazon Video</h5>
<p>Amazon Video offers high quality subtitles that can be downloaded in the <cite><a href="https://www.w3.org/TR/2006/CR-ttaf1-dfxp-20061116/"><em>DFXP format</em></a></cite> using Google Chrome’s Developer Tools. To get the subtitles, you need to start streaming the requested movie. Therefore, being a Prime member is very helpful as it includes free access to a large portion of the video content. Otherwise, gathering the subtitles for a large sample of movies could become rather expensive.</p>

<p><a href="/assets/images/subtitles-target-audience/screenshot.png"><img src="/assets/images/subtitles-target-audience/screenshot.png" alt="Subtitles Screenshot" style="max-width: 668px" /></a></p>

<ol>
  <li>Visit the movie’s product page (e.g. <cite><a href="https://www.amazon.com/dp/B01CUVU7DQ/">amazon.com/dp/B01CUVU7DQ</a></cite>)</li>
  <li>Open <em>Developer Tools</em></li>
  <li>Select the <em>Network</em> tab</li>
  <li>Click the <em>Watch Now</em> button</li>
  <li>Type ‘subtitle’ into the search bar</li>
  <li>Select <em>GetPlaybackResources?…</em> and open the <em>Preview</em> tab</li>
  <li>Open the URL under [subtitleURLs &gt; 0 &gt; url]</li>
  <li>Done!</li>
</ol>

<p>If you have any questions or concerns about this post, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>Text Analysis of YouTube Comments</title>
	  <link>//youtube-comments-text-analysis</link>
	  <author>CuriousGnu</author>
	  <pubDate>2017-02-28T11:00:00+01:00</pubDate>
	  <guid>//youtube-comments-text-analysis</guid>
	  <description><![CDATA[
	     <p>According to <cite><a href="http://www.alexa.com/topsites">Alexa.com</a></cite>, an Amazon subsidiary that analysis web traffic, YouTube is the world’s most popular social media site. Its user numbers even exceed those of web giants such as Facebook or Wikipedia. Over the past twelve years, YouTube has become a diverse platform where users can find and watch videos in a wide variety of genres, from cute cats to recorded university lectures.</p>

<p>Even though user comments are an integral part of the YouTube community, the comment section is also infamous as a home for trolls, negativity, and insults. For me, the broad acceptance of YouTube makes its user comments an interesting subject that’s worth a closer look. My plan for this post is to use text analysis to find out more about YouTube comments and determine whether they differ among certain categories.</p>

<h4 id="dataset">Dataset</h4>
<p>To download a large set of YouTube comments, I used a Python script that uses the official <cite><a href="https://developers.google.com/youtube/v3/">YouTube API</a></cite>, which (fortunately) offers generous API limits, allowing us to gather hundreds of thousands of individual comments. For this analysis, I decided to download only comments that refer to one of twenty selected channels in one of the following four categories: comedy, science, TV, and news &amp; politics (see table below). I used Socialblade’s <cite><a href="http://socialblade.com/youtube/top/100">YouTube top list</a></cite> as a guideline. However, I also took the liberty of excluding some channels that didn’t fit the category or targeted non-English-speaking viewers.</p>

<table style="font-size:14px">
  <thead>
    <tr>
      <th>Category</th>
      <th>Channels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>comedy</td>
      <td>PewDiePie, SMOSH, CollegeHumor, FailArmy, JennaMarbles</td>
    </tr>
    <tr>
      <td>science</td>
      <td>AsapSCIENCE, SciShow, Numberphile, ScienceChannel, Veritasium</td>
    </tr>
    <tr>
      <td>TV</td>
      <td>Jimmy Fallon, Conan, James Corden,  Jimmy Kimmel, TheEllenShow</td>
    </tr>
    <tr>
      <td>news &amp; politics</td>
      <td>TYT, ABCNews, CNN, Infowars, Vox</td>
    </tr>
  </tbody>
</table>

<p>Of these channels, the 25 most-watched videos between the years 2015 and 2016 were identified. For each of these videos, up to 500 of the most relevant comments were downloaded. Users responding to other users were ignored to ensure that each comment was an independent contribution. After letting the Python script run for about 1 hour, I ended up with a dataset containing just over 350,000 comments. You can find the script and the R script for the following analysis here: <a href="https://s3.amazonaws.com/cgcdn-misc/yt_comments_code.zip">yt_comments_code.zip</a>.</p>

<h4 id="analysis">Analysis</h4>
<p>For the analysis, I switched from Python to R so that I could use the <cite><a href="https://cran.r-project.org/web/packages/quanteda/">quanteda</a></cite> package, a handy toolset for quantitative text analysis. First, I generated a comparison word cloud for the four previously defined categories. In contrast to a traditional world cloud, in which the font sizes represent the words’ numbers of occurrences, a comparison word cloud illustrates which words are primarily used in specific categories. Therefore, the text size is linked to a word’s maximum deviation from its rate of occurrence in a category and the average across all comments.</p>

<p><a href="/assets/images/youtube-comments/wordcloud.png"><img src="/assets/images/youtube-comments/wordcloud.png" alt="YouTube Comments Wordcloud" style="max-width: 600px" /></a></p>

<p>The comparison word cloud shows that while viewers of news videos commented on political and social issues (e.g., <em>trump</em>, <em>racist</em>), comments on videos in the TV category contained more positive words (e.g., <em>love</em>, <em>funny</em>, <em>lol</em>). Furthermore, presumably topic-related keywords characterized comments from the science channels, while the use of profanity appears to be more prevalent in the comment sections of comedy videos.</p>

<p>These findings lead to the question: do viewers’ contributions significantly differ across the four categories regarding complexity and the use of profanity? A readability measurement like <cite><a href="https://en.wikipedia.org/wiki/SMOG">SMOG</a></cite> could be used to measure the complexity of a text. Even though such formulas are sometimes used on text snippets like tweets (e.g., <cite><a href="http://time.com/2958650/twitter-reading-level/">Times</a></cite>), I’m not convinced that it is an appropriate approach because brief internet comments and tweets differ substantially from the newspaper articles and business writing for which most of these measurements were originally designed.</p>

<p>Therefore, I chose a much simpler approach by using the word count of a comment as an indicator for the comment’s complexity. While this indicator cannot, of course, account for the actual context of a comment, it can be a rough estimate of how much effort a viewer put into commenting on a video. Regarding the use of profanity, a comment was classified as profane if it contained at least one profane word. The source of the used swear-word list is <a href="http://www.noswearing.com/dictionary">noswearing.com</a>. The following bar chart shows the average word length for the four categories and the share of profane comments.</p>

<p><a href="/assets/images/youtube-comments/bar_chart_01.png"><img src="/assets/images/youtube-comments/bar_chart_01.png" alt="YouTube Comments Bar Chart 1" style="max-width: 500px" /></a></p>

<p>We can see that the average comments on videos in the science and news channels are 20 and 24 words respectively, or about twice as long as the comments on videos in the TV and comedy category. With 15% of profane comments, the news channels have the highest share of profanity, whereas the science channels have the lowest rate, at just 5%. Furthermore, a Kruskal-Wallis test and chi-squared test (+post hoc tests) confirmed that the found differences are statistically significant.</p>

<p>Next, a sentiment analysis was used to determine the polarity of the comments, thereby classifying whether they are positive, negative, or neutral. For this analysis, I employed the <cite><a href="https://cran.r-project.org/web/packages/syuzhet/">Syuzhet</a></cite> R-package, which uses a straightforward knowledge-based technique based on lexicons, which are collections of positive and negative words. In the settings, I chose the <cite><a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">bing</a></cite> lexicon by Minqing Hu and Bing Liu. The next bar chart shows what many percentage of the comments in each category are classified as positive, negative, or neutral.</p>

<p><a href="/assets/images/youtube-comments/bar_chart_02.png"><img src="/assets/images/youtube-comments/bar_chart_02.png" alt="YouTube Comments Bar Chart 2" style="max-width: 700px" /></a></p>

<p>The news category, at 38%, has not only the highest share of negative comments, but also the lowest percentage (36%) of neutral comments. Considering that political issues are often polarizing topics, this result seems to be reasonable. Interestingly, the TV category, with 32% and 21%, has the highest share of positive and the lowest share of negative comments respectively.</p>

<h4 id="summary">Summary</h4>
<p>Overall, the analysis of over 350,000 comments shows that their style and content differs substantially across certain YouTube categories. While the average comments on videos about news and politics are longer than comments on other types of content, they also contain significantly more profanity and negativity. Compared to this category, science channels attract comments that are roughly as long, but contain much less profanity. Surprisingly, the comments in the TV category are largely family-friendly and positive. One explanation might be that these channels moderate the comments more strictly than the average news or comedy YouTubers.</p>

<p>If you have any questions or concerns about this post, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>Dataset: Yearly Bills of Mortality from 1657 to 1758</title>
	  <link>//yearly-bills-of-mortality-1657-1758</link>
	  <author>CuriousGnu</author>
	  <pubDate>2017-02-22T11:00:00+01:00</pubDate>
	  <guid>//yearly-bills-of-mortality-1657-1758</guid>
	  <description><![CDATA[
	     <p>In this blog post, I would like to share the <em>Yearly Bills of Mortality</em> dataset that I recently generated. The <em>Bills of Mortality</em> were a mortality statistic for London and were first published in the 17th century. Besides the number of deaths, they also provide information about the cause of death since 1629. The first time I read about these documents was in a <cite><a href="http://www.telegraph.co.uk/news/science/science-news/8934045/Historic-medical-records-show-deaths-from-lethargy-and-itch.html">newspaper article</a></cite> in The Telegraph about the absurdly sounding causes of death such as itch, lethargy, or grief.</p>

<p><a href="/assets/images/bills-of-mortality/itch.jpg"><img src="/assets/images/bills-of-mortality/itch.jpg" alt="Bills of Mortality - Itch" style="max-width: 300px" /></a></p>

<p>Interestingly, Google digitized the book <em>“Collection of Yearly Bills of Mortality, from 1657 to 1758 Inclusive”</em> and made it available through <cite><a href="https://books.google.com/books/about/Collection_of_Yearly_Bills_of_Mortality.html?id=3wYAAAAAMAAJ">Google Books</a></cite>. In addition to that, <cite><a href="https://archive.org/details/collectionyearl00hebegoog">archive.org</a></cite> offers those scans in a variety of formats. Unfortunately, Google’s optical character recognition (OCR) does not work particularly well on historical documents especially if the data is presented in tables, which makes searching the PDF and analyzing the changes in certain numbers difficult.</p>

<p>Finding those kinds of statistics rather intriguing, I considered the <em>Yearly Bills of Mortality</em> to be a perfect test case for manual data entry services that I am currently testing. The task was to convert the “Diseases and Casualties” table of 102 pages into an Excel table. In the case of different variants of the same causes of death (e.g., <em>hang’d</em> and <em>hanged</em>), a consistent form of spelling was used.</p>

<p><a href="/assets/images/bills-of-mortality/page.jpg"><img src="/assets/images/bills-of-mortality/page.jpg" alt="Bills of Mortality - Page" style="max-width: 500px" /></a></p>

<p>If you are also interested in this subject or just want to explore what killed Londoners between the years 1657 and 1758, you can download the complete dataset here <cite><a href="https://s3.amazonaws.com/cgcdn-misc/yearly_bills_of_mortality_1657_1758.zip">CSV file</a></cite>. Additionally, I uploaded the data to <cite><a href="https://public.tableau.com/profile/curious.gnu#!/vizhome/YearlyBillsofMortality1657-1758/Dashboard1">Tableau Public</a></cite>; you can try it out in the interactive graph below. Please note that I of course cannot guarantee the accuracy of the dataset.</p>

<div class="tableauPlaceholder" id="viz1487713662489" style="position: relative"><noscript><a href="https:&#47;&#47;www.curiousgnu.com"><img alt="Dashboard 1 " src="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ye&#47;YearlyBillsofMortality1657-1758&#47;Dashboard1&#47;1_rss.png" style="border: none" /></a></noscript><object class="tableauViz" style="display:none;"><param name="host_url" value="https%3A%2F%2Fpublic.tableau.com%2F" /> <param name="site_root" value="" /><param name="name" value="YearlyBillsofMortality1657-1758&#47;Dashboard1" /><param name="tabs" value="no" /><param name="toolbar" value="no" /><param name="static_image" value="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ye&#47;YearlyBillsofMortality1657-1758&#47;Dashboard1&#47;1.png" /> <param name="animate_transition" value="yes" /><param name="display_static_image" value="yes" /><param name="display_spinner" value="yes" /><param name="display_overlay" value="yes" /><param name="display_count" value="yes" /></object></div>
<script type="text/javascript"> var divElement = document.getElementById('viz1487713662489'); var vizElement = divElement.getElementsByTagName('object')[0]; vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px'; var scriptElement = document.createElement('script'); scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement); </script>
<p><br /></p>

<p>In case the graph does not work in your browser, please use this direct link <cite><a href="https://public.tableau.com/profile/curious.gnu#!/vizhome/YearlyBillsofMortality1657-1758/Dashboard1">public.tableau.com</a></cite>. If you have questions or concerns, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>Visualization: Traffic Collisions in Manhattan</title>
	  <link>//manhattan-traffic-collitions</link>
	  <author>CuriousGnu</author>
	  <pubDate>2017-02-09T11:00:00+01:00</pubDate>
	  <guid>//manhattan-traffic-collitions</guid>
	  <description><![CDATA[
	     <p>Today’s blog post is a visualization of traffic collisions in New York City. The New York Police Departmentpublishes information about motor vehicle collisions on the official <a href="https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95">NYC OpenData</a> platform. The dataset contains nearly one million incidents going back to the year 2012. For the following visualizations, I only looked at accidents that occurred during the year 2016 in Manhattan (n=36,680).</p>

<p>My first idea was to display all last year’s collisions on an animated map. For this type of task, <a href="https://carto.com/">CARTO</a> (formerly CartoDB) is an excellent freemium service that allows users to create custom maps. Usually, you can upload the OpenData CSV files directly to CARTO; however, for one-fifth of the incidents, no GPS coordinates are provided, and only streets or intersections are given. This lack of information makes a process called geocoding necessary, which transforms postal addresses to geographic coordinates. Due to the relatively large sample size (n=6,301), the free geocoding option of CARTO wasn’t sufficient, so I used the website, <a href="https://geocod.io/">Geocodio</a>, which offers a very affordable pay-as-you-go plan. For this map, I differentiated between collisions that lead to material damage or personal injury.</p>

<iframe width="100%" height="530" frameborder="0" src="https://curiousgnu.carto.com/viz/4fba7a94-ec7b-11e6-b3db-0e233c30368f/embed_map" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>

<p>Aside from this, we can of course also use the data for other types of plots. The following line plots compare the number of collisions between times of day and months.</p>

<p><a href="/assets/images/manhattan-traffic-collisions/line_charts.png"><img src="/assets/images/manhattan-traffic-collisions/line_charts.png" alt="Traffic Collitions in 2016 in Mannhattan" style="max-width: 550px" /></a></p>

<p>In addition to these simple visualizations, it could be interesting to check how the weather affects the number of accidents (<a href="https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets">climatological data</a>). If you have questions, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>Age Differences of Celebrity Couples</title>
	  <link>//age-differences-celebrity-couples</link>
	  <author>CuriousGnu</author>
	  <pubDate>2017-01-26T13:00:00+01:00</pubDate>
	  <guid>//age-differences-celebrity-couples</guid>
	  <description><![CDATA[
	     <p>In one of my <a href="https://www.curiousgnu.com/imdb-age-gap">first posts</a>, I wrote about the age difference of movie couples and showed that the male is, on average, slightly older than his partner. The goal of this article is to find out whether there is a similar trend among real celebrity couples. Even though the age difference in sexual relationships is a frequent subject of proper scientific studies, I thought it would be still interesting to take a closer look at stars’ dating lives.</p>

<p>As a data source, I scraped the website <a href="http://www.whosdatedwho.com/">whosdatedwho.com</a> (WDW), which collects information about the dating history of celebrities. Since it is a typical gossip site, and also relies on rumors, it must be expected that some of the data is inaccurate or incomplete. Nevertheless, this should be acceptable for our use case. The web-scraping provided data on 53,820 celebrities (dataset: 2016/12/06). To ensure the relevance of the data, I only included relationships which started in the past 50 years in the sample where at least one partner had been among the 5,000 most searched celebrities (WDW Rank). In addition, I removed all relationships from the sample for which the birthdates of both partners were not available. After applying all the criteria, the sample consisted of 6,693 relationships.</p>

<p>While extracting the data from the HTML source was a straightforward process with the Python library, <a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a>, it was surprising that WDW doesn’t provide any information about gender. In cases where the sex couldn’t be derived from the occupation (e.g., actor/actresses), I used <a href="https://genderize.io/">genderize.io</a> to determine the gender from the first name and manually checked unclear cases.</p>

<p>To visualize the data, we can use a program like <a href="https://gephi.org/">Gephi</a> to plot the relationships as a network. For the following figure, I used Gephi’s ego network filter with a depth setting of 2 to illustrate to whom <em>Alexander Skarsgård</em>, a Swedish actor, was directly and indirectly connected.</p>

<p><a href="/assets/images/age-differences-celebrity-couples/net.png"><img src="/assets/images/age-differences-celebrity-couples/net.png" alt="Whosdatedwho.com Network" style="max-width:500px" /></a></p>

<p>This figure indicates that both <em>Alexander Skarsgård</em> and <em>Marilyn Manson</em>, an American singer, dated the actress <em>Evan Rachel Wood</em>. Next, let’s look at the ages of the partners at the start of their (alleged) relationships. The 2D density plot shows the age of the male partner on the x-axis and the age of the female partner on the y-axis. The plot suggests that, in many cases, the man is slightly older than his female partner, a difference that gets bigger with the increasing age of the male. Overall, this age disparity is similar to the age difference among married couples in Western countries (<a href="https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships">Wikipedia</a>).</p>

<p><a href="/assets/images/age-differences-celebrity-couples/density.png"><img src="/assets/images/age-differences-celebrity-couples/density.png" alt="Couples - Density Plot" style="max-width:500px" /></a></p>

<p>To visualize the age difference across certain age groups, I used the R package <a href="https://cran.r-project.org/web/packages/yarrr/index.html">yarrr</a> for the next pirate plot. The plot illustrates that the age disparity in new relationships increases significantly when male celebrities get older. While male stars in their <strong>20s</strong> have female partners  <strong>2.4 years</strong> older on average, the women in new relationships with <strong>40- to 49-year-olds</strong> and <strong>over-50s</strong> are about <strong>6.0</strong> and <strong>16.5 years younger</strong>, respectively.</p>

<style type="text/css">
	.tg-ba  {border-collapse:collapse;border-spacing:0;border:none;max-width: 400px;border-top: 2px #333 solid;border-bottom: 2px #333 solid;}
	.tg-ba td{font-size:14px;padding:1px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;background-color:#fff!important;text-align:center}
	.tg-ba th{font-size:14px;font-weight:normal;padding:1px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;background-color:#fff!important;text-align:center;border-bottom: 1px #333 solid;}
	.tg-ba .tg-c9cr{font-style:italic}
	.tg-ba .tg-wxgh{text-decoration:underline;vertical-align:top}
	.tg-ba .tg-yw4l{vertical-align:top}
	.tg-ba .tg-db0a{text-decoration:underline}
</style>

<center>
	<table class="tg-ba">
		<tr>
			<th class="tg-031e"></th>
			<th class="tg-c9cr" colspan="2">age difference</th>
			<th class="tg-yw4l"></th>
		</tr>
		<tr>
			<td class="tg-db0a">age (male)</td>
			<td class="tg-db0a">mean</td>
			<td class="tg-wxgh">median</td>
			<td class="tg-wxgh">n</td>
		</tr>
		<tr>
			<td class="tg-031e">20-29</td>
			<td class="tg-031e">-2.39</td>
			<td class="tg-yw4l">-1</td>
			<td class="tg-yw4l">420</td>
		</tr>
		<tr>
			<td class="tg-031e">30-39</td>
			<td class="tg-031e">0.51</td>
			<td class="tg-yw4l">1</td>
			<td class="tg-yw4l">3,170</td>
		</tr>
		<tr>
			<td class="tg-031e">40-49</td>
			<td class="tg-031e">5.99</td>
			<td class="tg-yw4l">7</td>
			<td class="tg-yw4l">2,130</td>
		</tr>
		<tr>
			<td class="tg-031e">50+</td>
			<td class="tg-031e">16.47</td>
			<td class="tg-yw4l">17</td>
			<td class="tg-yw4l">973</td>
		</tr>
	</table>
</center>

<p><a href="/assets/images/age-differences-celebrity-couples/pirate.png"><img src="/assets/images/age-differences-celebrity-couples/pirate.png" alt="Couples - Pirate Plot" style="max-width:500px" /></a></p>

<p>A regression analysis can be applied to examine the relationship between female and male age further. To automatically account for non-linearity, I chose <a href="https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines">MARS</a> (<a href="https://cran.r-project.org/web/packages/earth/index.html">earth</a> R package). The result shows the age difference changes with the increasing age of the male partner. The shaded area is the 90% prediction interval. According to the model, the new partner (female) of a <strong>40-year-old</strong> male celebrity who started dating is on average <strong>9.8 years younger</strong>.</p>

<p><a href="/assets/images/age-differences-celebrity-couples/regression.png"><img src="/assets/images/age-differences-celebrity-couples/regression.png" alt="Couples - Pirate Regression" style="max-width:600px" /></a></p>

<p>Overall, the data shows that the often criticized age difference among movie couples may not be too far from reality, or at least the reality of some celebrities. If you have questions or concerns, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>A Darknet Site Currently Offers 42,497 U.S. Credit Cards</title>
	  <link>//darknet-credit-cards</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-09-06T03:00:00+02:00</pubDate>
	  <guid>//darknet-credit-cards</guid>
	  <description><![CDATA[
	     <p>Last week, I found out that my credit card information was stolen and used by criminals for an expensive shopping spree. This incident inspired me to revisit my <a href="https://www.curiousgnu.com/cryptomarkets-lsd-sales">previous post</a> about drug dealing on the Darknet and research how stolen credit cards are traded there. I was able to gather a dataset of <strong>42,497</strong> stolen U.S. credit cards which are currently sold on a Darknet site. At the end of this post, you’ll find a link to a site that allows you to see if your card is in this dataset.</p>

<p>The Darknet, a part of the internet which is only accessible with special software like the <a href="https://www.torproject.org/projects/torbrowser.html.en">Tor Browser</a>, allows users and website owners to stay anonymous. The anonymity not only makes the Darknet an essential tool for people like reporters or activists, but is also used widely by criminals. Nowadays the Darknet hosts multiple <a href="https://en.wikipedia.org/wiki/Darknet_market">Cryptomarkets</a>, which are marketplaces similar to eBay where vendors can sell products like illicit drugs, counterfeit money, or stolen credit cards. I decided to take a close look at the AlphaBay Market because it’s one of the largest marketplaces and relatively easy to scrape.</p>

<p><a href="/assets/images/darknet-credit-cards/alphabay_screenshot.png"><img src="/assets/images/darknet-credit-cards/alphabay_screenshot.png" alt="AlphaBay - Screenshot" style="max-width: 600px" /></a></p>

<p>The AlphaBay Market has a feature called <em>CC Autoshop</em> that allows potential buyers to search a database of all the stolen credit cards that are offered by different sellers. For example, it’s possible to only search for cards from a particular city. That’s important for criminals who try to circumvent anti-fraud measures by using stolen cards from the same region or state in which they are located. But it also means that the sellers have to reveal information that we can analyze.</p>

<p>First, I downloaded the entire <em>CC Autoshop</em> as HTML files before I used the Python library <em>Beautiful Soup</em> to extract the information. I got 42,497 U.S. credit cards which were offered on September 1st, 2016 as a result. The total value of is <strong>$324,941</strong> with an average price of <strong>$7.65 per card</strong>. Some cards (1025) even include the Social Security number of the owner. Considering that nearly <a href="http://www.creditcards.com/credit-card-news/credit-card-security-id-theft-fraud-statistics-1276.php">13 million Americans</a> are victims of identity fraud each year, this number almost seems insignificant, but it can nevertheless cause millions of dollars in damages. What I find particularly concerning is that anyone can purchase these cards after doing basic internet research.</p>

<p><a href="/assets/images/darknet-credit-cards/map.jpg"><img src="/assets/images/darknet-credit-cards/map.jpg" alt="AlphaBay - Countries" /></a></p>

<p>The map above shows how many cards from each state are offered on the AlphaBay Market. It is suprising that <strong>27%</strong> (11,338) of them are from Delaware and are sold by only two major sellers (<em>Sasha_Grey</em> and <em>HotPizza</em>). Unfortunately, I can only speculate about the reasons for this. Are those just company credit cards or does it suggest a local card breach? The following graph is an overview of all active AlphaBay CC vendors based on the total number of cards they offer.</p>

<p><a href="/assets/images/darknet-credit-cards/treemap.png"><img src="/assets/images/darknet-credit-cards/treemap.png" alt="AlphaBay - Treemap" style="max-width: 600px" /></a></p>

<p>If you would like to check whether your credit card is in the dataset, you can either download it as a <a href="https://www.curiousgnu.com/assets/data/cc_autobuy_public.csv.gz">CSV file</a> or use the following site to search the database: <a href="https://www.curiousgnu.com/assets/tools/cc.html">www.curiousgnu.com/assets/tools/cc.html</a></p>

<h4 id="how-to-scrape-darknet-sites">How to scrape Darknet sites?</h4>

<p>Scraping <a href="https://www.torproject.org/docs/hidden-services.html.en"><em>hidden services</em></a> in the Tor network (Darknet sites) is very similar to regular web scraping with the exception that most <em>hidden services</em> don’t use JSON APIs, meaning that you have to extract the information from an HTML file. My preferred method is first to download all pages as HTML files before using Python and <em>Beautiful Soup</em> to extract the information I need. The following steps should work on OS X and Linux systems.</p>

<p><a href="/assets/images/darknet-credit-cards/alphabay_curl_web.png"><img src="/assets/images/darknet-credit-cards/alphabay_curl_web.png" alt="AlphaBay - CURL" style="max-width: 500px" /></a></p>

<ol>
  <li>Visit the site you want to scrape in the Tor Browser.</li>
  <li>Open the Web Console (<em>Right Click &gt; Inspect Element</em>).</li>
  <li>Go to the <em>Network</em> Tab.</li>
  <li>Right click on the main GET request (see Domain column) and select Copy as cURL to copy the curl command to replicate the request.</li>
  <li>Do not close the Tor browser.</li>
  <li>Before you can run the curl command in the Terminal, add the following options to the end of it <strong><em>’–socks5-hostname 127.0.0.1:9150 –output o.html’</em></strong>. It tells curl to use the Tor client and save the output to o.html.</li>
  <li>In case you want to download multiple pages, you can use the bash <em>for loop</em> like this 
<strong><em>‘for i in {1..10}; do curl […] page=${i} –output ${i}.html; done’</em></strong>.</li>
  <li>Follow the Beautiful Soup <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a> to extract the need information from the saved HTML files.</li>
</ol>

<p>If you have questions or concerns, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>


	  ]]></description>
	</item>

	<item>
	  <title>Almost 80% of Private Day Traders Lose Money</title>
	  <link>//day-trading</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-08-17T03:00:00+02:00</pubDate>
	  <guid>//day-trading</guid>
	  <description><![CDATA[
	     <p>A few months ago, I wrote a <a href="http://www.curiousgnu.com/penny-auctions">blog post</a> about how penny auction sites make you money. As a reaction, some readers sent me links to day trading brokers that promise easy returns. These brokers allow private investors to hold stocks or currencies positions for a short time which makes it possible to speculate on small price changes. Many day traders use the margin and leverage to increase the size of their positions by lending money from their brokers.</p>

<p>For example, a 1:10 leverage increases the profits by the factor 10 but also the potential losses. Strictly speaking, only trading within a day is called day trading. For this post, I’ll use a broader definition which also includes leveraged short-term trades where the positions are held for multiple days.</p>

<p><img src="/assets/images/day-trading/banner.png" alt="Forex Banner" /></p>

<p>In contrast to many penny auctions sites, these brokers are mostly legitimate and are regulated companies. However, this fact doesn’t make this kind of trading any less risky. My goal is to find out if the average investor profits from day trading.</p>

<h4 id="data">Data</h4>
<p>The data source for this post is <a href="https://en.wikipedia.org/wiki/EToro"><em>eToro</em></a>, a brokerage company that offers a feature called <a href="https://www.etoro.com/en/social-trading/">Social Trading</a>, which is social network for traders. It is enabled by default and allows users to view and copy other users’ trades. Therefore, everyone’s trading performance is publicly available who have not disabled Social Trading.</p>

<p>On the 1st of August, 2016, I downloaded the publicly available data through their ranking API. I selected all users who were active during the past twelve months, traded with real money, and had at least three trades. The results consist of <strong>83.3k traders</strong> who fulfill these conditions. If you’re interested in how you can access the (undocumented) API, I recommend you to open Chrome’s <em>DevTools</em>, while you’re on eToro’s Discover People page.</p>

<h4 id="results">Results</h4>
<p>The following histogram shows the average gains of each trader over the past twelve months. In the end, <strong>79.5%</strong> of them lost real money. The median 12-month returns were <strong>-36.3%</strong>.</p>

<p><a href="/assets/images/day-trading/histogram.png"><img src="/assets/images/day-trading/histogram.png" alt="eToro 12M Gains" /></a></p>

<p>Besides the investing performance, the data also reveals from which countries the traders are coming. With a share of <strong>15.7%</strong>, the UK leads the list of most common countries followed by Germany with a share of <strong>11.3%</strong>. The US doesn’t appear in this list because <em>eToro</em> isn’t available in the US market, presumably due to stricter regulations.</p>

<p><a href="/assets/images/day-trading/barchart.png"><img src="/assets/images/day-trading/barchart.png" alt="eToro Customers by Country" style="max-width: 720px" /></a></p>

<h4 id="conclusion">Conclusion</h4>
<p>The results show that day-trading is a highly risky investment on which most traders end up losing money. I wouldn’t go so far as to say that it’s impossible to make a profit in the long-term but apparently there is no easy method (e.g. technical analysis or social trading) to do it. I would be very careful, if someone promises easy money by trading based on simple patterns or trading signals.</p>


	  ]]></description>
	</item>

	<item>
	  <title>These Are The Most Dangerous PokeStops in NYC</title>
	  <link>//pokemon-go</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-08-09T03:00:00+02:00</pubDate>
	  <guid>//pokemon-go</guid>
	  <description><![CDATA[
	     <p>Pokemon GO quickly became one of the most popular mobile games. In cities all around the world, you can see people searching for Pokemon and battling other players in Poke Gyms. While exploring this new augmented reality, it’s easy to forget about the dangerous of the real word. On a daily basis, news sites report on Pokemon Go related incidents like <a href="https://www.washingtonpost.com/news/morning-mix/wp/2016/08/02/arizona-couple-accused-of-abandoning-son-for-pokemon-go/">child abandonment</a>, <a href="https://www.theguardian.com/australia-news/2016/jul/29/pokemon-go-player-crashes-car-into-school-while-playing-game">reckless driving</a>, or <a href="http://reut.rs/2aJ8W9n">trespassing</a>. Earlier this month New York Governor Andrew M. Cuomo even <a href="http://www.npr.org/sections/alltechconsidered/2016/08/02/488435018/new-york-bans-registered-sex-offenders-from-pok-mon-go">banned sex offenders</a> from playing the game.</p>

<p>These incidents gave me the idea for this article about <a href="https://support.pokemongo.nianticlabs.com/hc/en-us/articles/221957688">PokeStops</a> in potentially unsafe areas where caution is advised. My goal was to analyze public data to identify PokeStops in New York City which are close to crime scenes and registered sex offenders.</p>

<h4 id="pokestops-near-crime-scenes">PokeStops Near Crime Scenes</h4>

<p>First, I used <a href="http://www.pokemongomap.info/">PokemonGOMap.info</a> to get the locations of the 24 thousand PokeStop in NYC and download all reported felonies of 2015 (103k) from the <a href="https://data.cityofnewyork.us/Public-Safety/NYPD-7-Major-Felony-Incidents/hyij-8hr7">NYC OpenData portal</a>. For this analysis, I exclude the offenses <em>burglary</em> (15k) and <em>grand larceny</em> (49k) because they’re less a potential threat to players in the area. The following map shows all PokeStops as blue dots whereas incidents of <em>felony assault &amp; robbery</em> (37k) are represented by green dots and <em>murder &amp; rape</em> (1.5k) by red dots.</p>

<p><a href="/assets/images/pokemon-go/incidents.jpg"><img src="/assets/images/pokemon-go/incidents.jpg" alt="Incidents" /></a></p>

<p>Next, I loaded the raw data into <a href="https://cran.r-project.org/">R</a>* to count all crimes that occurred within 150m (492ft) of each PokeStop. I had to choose this rather large area because the public data doesn’t show the exact location of the incidents due to privacy reason. Instead, it only provides the midpoint of the street segment on which they happened.</p>

<p>The map below shows the top ten PokeStop in which proximity most major felony incidents occurred. For this map, the offenses murder and rape are weighted by the factor five and only the top PokeStops of an NTA are included to reduce regional clusters. You can find the total number of murders &amp; rapes in the areas of the PokeStops in the red boxes and total number of felony assaults &amp; robberies in the yellow boxes right next to them. The average number of incidents of all NYC PokeStops stands at <strong>0.15</strong> for murder or rape and <strong>4.00</strong> for <em>felony assault</em> or <em>robbery</em>.</p>

<p><a href="/assets/images/pokemon-go/top_pokespots.png"><img src="/assets/images/pokemon-go/top_pokespots.png" alt="Most Dangerous PokeStops" /></a></p>

<h4 id="pokestops-close-to-sex-offenders">PokeStops Close to Sex Offenders</h4>

<p>Another question I researched was how many registered sex offenders live close to PokeStops. I downloaded their addresses from the website <a href="http://familywatchdog.us/">familywatchdog.us</a>. For the analysis I only selected people who were convicted for offenses against children and/or rape. The following map shows all PokeStops with the color of the dots indicating how many registered sex offenders live in a 150m (492ft) radius.</p>

<p><a href="/assets/images/pokemon-go/sex_offender.jpg"><img src="/assets/images/pokemon-go/sex_offender.jpg" alt="Sex Offender" /></a></p>

<p>The numbers show that <strong>11.4%</strong> of all PokeStops in NYC have at least one sex offender living nearby. The next table lists the top ten PokeStops by the total number of offenders living within 150m.</p>

<table style="font-size:14px">
  <thead>
    <tr>
      <th>#</th>
      <th>PokeStop</th>
      <th>Address</th>
      <th>Sex Offender (within 150m)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Iglesia Church of Salvation</td>
      <td><a href="http://maps.google.com/?q=3110%20Church%20Ave%2C%20Brooklyn%2C%20NY%2011226" target="_blank">3110 Church Ave, Brooklyn, NY 11226</a></td>
      <td>11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Center For Figurative Painting</td>
      <td><a href="http://maps.google.com/?q=261%20W%2035th%20St%2C%20New%20York%2C%20NY%2010001" target="_blank">261 W 35th St, New York, NY 10001</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Power Shield Art</td>
      <td><a href="http://maps.google.com/?q=252%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">252 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Garment Wear Arcade</td>
      <td><a href="http://maps.google.com/?q=306%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">306 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>5</td>
      <td>Houndstooth Pub</td>
      <td><a href="http://maps.google.com/?q=266%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">266 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>6</td>
      <td>Chill Cat</td>
      <td><a href="http://maps.google.com/?q=247-265%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">247-265 W 37th St, New York, NY 10018</a></td>
      <td>9</td>
    </tr>
    <tr>
      <td>7</td>
      <td>Church</td>
      <td><a href="http://maps.google.com/?q=1800%20Bedford%20Ave%2C%20Brooklyn%2C%20NY%2011225" target="_blank">1800 Bedford Ave, Brooklyn, NY 11225</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>8</td>
      <td>The Theatre Building</td>
      <td><a href="http://maps.google.com/?q=312%20W%2036th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">312 W 36th St, New York, NY 10018</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>9</td>
      <td>Memorial of Electrical Diagrams</td>
      <td><a href="http://maps.google.com/?q=555%208th%20Ave%2C%20New%20York%2C%20NY%2010018" target="_blank">555 8th Ave, New York, NY 10018</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Chanin Commemorative Plaque</td>
      <td><a href="http://maps.google.com/?q=41-99%20E%2041st%20St%2C%20New%20York%2C%20NY%2010017" target="_blank">41-99 E 41st St, New York, NY 10017</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>

<p>If you have questions or concerns, feel free to write me an <a href="mailto:contact@curiousgnu.com">email</a>.</p>

<p><small>*R packages used: <a href="https://cran.r-project.org/web/packages/ggmap/index.html">ggmap</a>, <a href="https://cran.r-project.org/web/packages/GISTools/index.html">GISTools</a>, <a href="https://cran.r-project.org/web/packages/rgeos/index.html">rgeos</a>, <a href="https://cran.r-project.org/web/packages/maptools/index.html">maptools</a> | Photo: “back at work” by <a href="https://flic.kr/p/9ze8bf">Michael Cory</a> is licensed under CC BY-NC 2.0</small></p>

	  ]]></description>
	</item>

	<item>
	  <title>Conan is The Dirtiest Late-Night Show on YouTube</title>
	  <link>//late-night-shows</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-07-13T03:00:00+02:00</pubDate>
	  <guid>//late-night-shows</guid>
	  <description><![CDATA[
	     <p>I had the idea for this blog post while I was watching some interviews on YouTube. The videos of the <a href="https://www.youtube.com/user/teamcoco"><em>Conan</em></a> show stood out to me because many of them seem to be focused on sexual topics. To me, it looks like they were following the simple “sex sells” approach. Not that there’s something inherently wrong with this, it just appears that <em>Conan</em> uses it much more than other late-night show channels.</p>

<p><a href="/assets/images/late-night-shows/screenshot.png"><img src="/assets/images/late-night-shows/screenshot.png" alt="Conan Search Results" style="max-width: 600px" /></a></p>

<p>This brought me to my main question. Are <em>Conan</em> videos more focused on sexual content than the ones of other late-night shows? I decided to compare its YouTube channel to the official channels of <a href="https://www.youtube.com/user/JimmyKimmelLive"><em>Jimmy Kimmel Live!</em></a>,  <a href="https://www.youtube.com/user/latenight"><em>The Tonight Show Starring Jimmy Fallon</em></a>, <a href="https://www.youtube.com/channel/UCMtFAi84ehTSYSE9XoHefig"><em>The Late Show with Stephen Colbert</em></a>, and <a href="https://www.youtube.com/user/TheLateLateShow"><em>The Late Late Show with James Corden</em></a>.</p>

<p>The public <a href="https://developers.google.com/youtube/v3/docs/videos/list">YouTube API</a> allowed me to download the information for all available 12,237 videos. To find out whether a video contains sexual content or not, I compared the video’s title and description against a word list (see below). If the title or description contains at least one of the words, the video will be rated as “contains sexual content”. On top of that, I also checked if the video titles contain names of persons to group the videos into three categories: female, male, and neutral. For example, interviews with actresses fall into the female category, whereas, monologs fall into the neutral category.</p>

<p><a href="/assets/images/late-night-shows/barplot.png"><img src="/assets/images/late-night-shows/barplot.png" alt="Late Night Show - Bar Plot" /></a></p>

<p>The graph above shows that <strong>17%</strong> of <em>Conan</em> videos in the female category contain sexual content which is <strong>11%</strong> more than the <em>Late Show with Stephen Colbert</em>, the second place. We also can see that the share of <em>Conan</em> videos containing sexual content is twice as large in the female category than in the male category.  These numbers confirm the hypothesis that the <em>Conan</em> YouTube channel focuses much more on sexual content than other late-night shows. <em>The Tonight Show Starring Jimmy Fallon appears</em> to be the YouTube channel with the cleanest video titles and descriptions.</p>

<p><strong>Bonus:</strong> The results left me wondering if suggestive titles help the channels to gain views. I created the following plot with the <a href="https://cran.cnr.berkeley.edu/web/packages/beanplot/">beanplot</a> R package which shows us that only <em>Conan</em> seems to benefit from sexual video titles or descriptions. If you’re interested in the beanplot, you can find a detailed explanation <a href="https://cran.cnr.berkeley.edu/web/packages/beanplot/vignettes/beanplot.pdf">here</a>.</p>

<p><a href="/assets/images/late-night-shows/beanplot.png"><img src="/assets/images/late-night-shows/beanplot.png" alt="Late Night Show - Bean Plot" style="max-width: 680px" /></a></p>

<pre><code>Word List: boob*, dating*, hooker*, kiss*, love scene*, naked*, naughty*, nude*, nudity*, orgasm*, panties*, penis*, porn*, prostitute*, sex*, slut*, strip*, topless*, whore*
</code></pre>

	  ]]></description>
	</item>

	<item>
	  <title>Chicago pays female employees only 80% of what it pays male employees</title>
	  <link>//pay-gap</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-07-05T03:00:00+02:00</pubDate>
	  <guid>//pay-gap</guid>
	  <description><![CDATA[
	     <p>While I was browsing through the City of <a href="https://data.cityofchicago.org/">Chicago’s Data Catalog</a>, I came across a <a href="https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w">dataset</a> of the city’s 32,000 employees which included their full names, position titles, and annual salaries. I thought that it was a great opportunity to find out whether the gender pay gap was a problem there also. The gender pay gap is the average difference between men’s and women’s earnings, which in the US is somewhere around <a href="http://www.iwpr.org/initiatives/pay-equity-and-discrimination">-21%</a> for women. It is an important number many politicians and activists use as proof for gender inequality.</p>

<p>Before I could compare the average salaries of female and male city employees, I needed to identify their gender – a piece of information which was not included in the official dataset. To do this, I used the R-Package <a href="https://cran.r-project.org/web/packages/gender/index.html"><em>gender</em></a> to predict the gender of a person based on his or her first name. Of course, this method isn’t 100% accurate, but because of the high number of employees, this potential inaccuracy shouldn’t be a problem. After that, I was able to compare the average annual salaries of male and female city employees. It turns out that the City of Chicago isn’t any better than the rest of the nation. It pays its female employees on average, only 80% of what their male colleagues make – which is very close to the national average of 79%.</p>

<p><a href="/assets/images/pay-gap/barchart.png"><img src="/assets/images/pay-gap/barchart.png" alt="Pay Gap Barchart" style="max-width: 500px" /></a></p>

<p>If you think now that there are many other factors besides gender, that determine a person’s salary, and that chart above is completely useless, you are right. It’s obviously not good enough to compare only the average earnings of both genders if they do different kinds of jobs. The criticism of how the gender pay gap is used in political discussions isn’t something new, and it has been proven many times that the gender pay gap isn’t a sufficient proof for gender inequality.</p>

<p>I think one of the problems with the arguments against the gender pay gap is that they often rely on statistical tests. Don’t get me wrong, these tests are the only scientifically correct way to do it; but unfortunately, many people stop listening to you as soon as you start mentioning t-tests and confidence levels. The reason why I find the Chicago dataset so interesting is that it contains the salaries of each employee, which allows us to use it as a real-world example to illustrate the problems with the gender pay gap argument. To do this, I propose a simple scatter plot to display the average male and female salaries per position title.</p>

<p><a href="/assets/images/pay-gap/sketch.png"><img src="/assets/images/pay-gap/sketch.png" alt="Pay Gap Sketch" style="max-width: 300px" /></a></p>

<p>So, each dot represents one job position, like police officer or police sergeant. If a dot (1) is below the 45-degree line, the average salary of men is higher than the average salary of women holding the same position. If a dot (2) is above the 45-degree line, it’s the other way around. In case the average salaries of both genders are equal, the dot (3) sits directly on the line. Based on this idea, I generated the following plot:</p>

<p><a href="/assets/images/pay-gap/scatter_plot.png"><img src="/assets/images/pay-gap/scatter_plot.png" alt="Pay Gap Scatter Plot" style="max-width: 600px" /></a></p>

<p>This plot clearly shows that women are not systematically paid 20% less for doing the same job as the first bar chart might have suggested.  The main reason for the difference is that women are doing different jobs than men do. Therefore, the gender pay gap shouldn’t be used as an argument for the existence of gender inequality but gender differences. I’m not saying that gender discrimination doesn’t exist in the workplace, it’s just that the gender pay gap doesn’t support the claim that women are paid 20% less for doing the same job. Therefore, a more honest way to use this statistic would be in a discussion about how both gender and personal choices affect careers.</p>

<p>In conclusion, it’s true that the gender pay gap exists, and that on average, women make less money than men. However, the claims that it proves gender inequality are false because women are simply doing different kinds of jobs.</p>

<p>If you have questions or concerns, feel free to write me an  <a href="mailto:contact@curiousgnu.com">email</a>.</p>

<p><small>Photo: “Chicago” by <a href="https://flic.kr/p/62vAsR">Tony Webster</a> is licensed under CC BY 2.0</small></p>

	  ]]></description>
	</item>


</channel>
</rss>
