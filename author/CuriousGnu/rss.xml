<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>www.curiousgnu.com</title>
   
   <link>http://www.curiousgnu.com/</link>
   <description>Numbers, Graphs, and Apple Strudels</description>
   <language>en-uk</language>
   <managingEditor> CuriousGnu</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>These Are The Most Dangerous PokeStops in NYC</title>
	  <link>//pokemon-go</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-08-09T03:00:00+02:00</pubDate>
	  <guid>//pokemon-go</guid>
	  <description><![CDATA[
	     <p>Pokemon GO quickly became one of the most popular mobile games. In cities all around the world, you can see people searching for Pokemon and battling other players in Poke Gyms. While exploring this new augmented reality, it’s easy to forget about the dangerous of the real word. On a daily basis, news sites report on Pokemon Go related incidents like <a href="https://www.washingtonpost.com/news/morning-mix/wp/2016/08/02/arizona-couple-accused-of-abandoning-son-for-pokemon-go/">child abandonment</a>, <a href="https://www.theguardian.com/australia-news/2016/jul/29/pokemon-go-player-crashes-car-into-school-while-playing-game">reckless driving</a>, or <a href="http://reut.rs/2aJ8W9n">trespassing</a>. Earlier this month New York Governor Andrew M. Cuomo even <a href="http://www.npr.org/sections/alltechconsidered/2016/08/02/488435018/new-york-bans-registered-sex-offenders-from-pok-mon-go">banned sex offenders</a> from playing the game.</p>

<p>These incidents gave me the idea for this article about <a href="https://support.pokemongo.nianticlabs.com/hc/en-us/articles/221957688">PokeStops</a> in potentially unsafe areas where caution is advised. My goal was to analyze public data to identify PokeStops in New York City which are close to crime scenes and registered sex offenders.</p>

<h4 id="pokestops-near-crime-scenes">PokeStops Near Crime Scenes</h4>

<p>First, I used <a href="http://www.pokemongomap.info/">PokemonGOMap.info</a> to get the locations of the 24 thousand PokeStop in NYC and download all reported felonies of 2015 (103k) from the <a href="https://data.cityofnewyork.us/Public-Safety/NYPD-7-Major-Felony-Incidents/hyij-8hr7">NYC OpenData portal</a>. For this analysis, I exclude the offenses <em>burglary</em> (15k) and <em>grand larceny</em> (49k) because they’re less a potential threat to players in the area. The following map shows all PokeStops as blue dots whereas incidents of <em>felony assault &amp; robbery</em> (37k) are represented by green dots and <em>murder &amp; rape</em> (1.5k) by red dots.</p>

<p><a href="/assets/images/pokemon-go/incidents.jpg"><img src="/assets/images/pokemon-go/incidents.jpg" alt="Incidents" /></a></p>

<p>Next, I loaded the raw data into <a href="https://cran.r-project.org/">R</a>* to count all crimes that occurred within 150m (492ft) of each PokeStop. I had to choose this rather large area because the public data doesn’t show the exact location of the incidents due to privacy reason. Instead, it only provides the midpoint of the street segment on which they happened.</p>

<p>The map below shows the top ten PokeStop in which proximity most major felony incidents occurred. For this map, the offenses murder and rape are weighted by the factor five and only the top PokeStops of an NTA are included to reduce regional clusters. You can find the total number of murders &amp; rapes in the areas of the PokeStops in the red boxes and total number of felony assaults &amp; robberies in the yellow boxes right next to them. The average number of incidents of all NYC PokeStops stands at <strong>0.15</strong> for murder or rape and <strong>4.00</strong> for <em>felony assault</em> or <em>robbery</em>.</p>

<p><a href="/assets/images/pokemon-go/top_pokespots.png"><img src="/assets/images/pokemon-go/top_pokespots.png" alt="Most Dangerous PokeStops" /></a></p>

<h4 id="pokestops-close-to-sex-offenders">PokeStops Close to Sex Offenders</h4>

<p>Another question I researched was how many registered sex offenders live close to PokeStops. I downloaded their addresses from the website <a href="http://familywatchdog.us/">familywatchdog.us</a>. For the analysis I only selected people who were convicted for offenses against children and/or rape. The following map shows all PokeStops with the color of the dots indicating how many registered sex offenders live in a 150m (492ft) radius.</p>

<p><a href="/assets/images/pokemon-go/sex_offender.jpg"><img src="/assets/images/pokemon-go/sex_offender.jpg" alt="Sex Offender" /></a></p>

<p>The numbers show that <strong>11.4%</strong> of all PokeStops in NYC have at least one sex offender living nearby. The next table lists the top ten PokeStops by the total number of offenders living within 150m.</p>

<table style="font-size:14px">
  <thead>
    <tr>
      <th>#</th>
      <th>PokeStop</th>
      <th>Address</th>
      <th>Sex Offender (within 150m)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Iglesia Church of Salvation</td>
      <td><a href="http://maps.google.com/?q=3110%20Church%20Ave%2C%20Brooklyn%2C%20NY%2011226" target="_blank">3110 Church Ave, Brooklyn, NY 11226</a></td>
      <td>11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Center For Figurative Painting</td>
      <td><a href="http://maps.google.com/?q=261%20W%2035th%20St%2C%20New%20York%2C%20NY%2010001" target="_blank">261 W 35th St, New York, NY 10001</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Power Shield Art</td>
      <td><a href="http://maps.google.com/?q=252%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">252 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Garment Wear Arcade</td>
      <td><a href="http://maps.google.com/?q=306%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">306 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>5</td>
      <td>Houndstooth Pub</td>
      <td><a href="http://maps.google.com/?q=266%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">266 W 37th St, New York, NY 10018</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>6</td>
      <td>Chill Cat</td>
      <td><a href="http://maps.google.com/?q=247-265%20W%2037th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">247-265 W 37th St, New York, NY 10018</a></td>
      <td>9</td>
    </tr>
    <tr>
      <td>7</td>
      <td>Church</td>
      <td><a href="http://maps.google.com/?q=1800%20Bedford%20Ave%2C%20Brooklyn%2C%20NY%2011225" target="_blank">1800 Bedford Ave, Brooklyn, NY 11225</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>8</td>
      <td>The Theatre Building</td>
      <td><a href="http://maps.google.com/?q=312%20W%2036th%20St%2C%20New%20York%2C%20NY%2010018" target="_blank">312 W 36th St, New York, NY 10018</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>9</td>
      <td>Memorial of Electrical Diagrams</td>
      <td><a href="http://maps.google.com/?q=555%208th%20Ave%2C%20New%20York%2C%20NY%2010018" target="_blank">555 8th Ave, New York, NY 10018</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Chanin Commemorative Plaque</td>
      <td><a href="http://maps.google.com/?q=41-99%20E%2041st%20St%2C%20New%20York%2C%20NY%2010017" target="_blank">41-99 E 41st St, New York, NY 10017</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>

<p>If you have questions or concerns, feel free to write me an <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">email</a>.</p>

<p><small>*R packages used: <a href="https://cran.r-project.org/web/packages/ggmap/index.html">ggmap</a>, <a href="https://cran.r-project.org/web/packages/GISTools/index.html">GISTools</a>, <a href="https://cran.r-project.org/web/packages/rgeos/index.html">rgeos</a>, <a href="https://cran.r-project.org/web/packages/maptools/index.html">maptools</a> | Photo: “back at work” by <a href="https://flic.kr/p/9ze8bf">Michael Cory</a> is licensed under CC BY-NC 2.0</small></p>

	  ]]></description>
	</item>

	<item>
	  <title>Conan is The Dirtiest Late-Night Show on YouTube</title>
	  <link>//late-night-shows</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-07-13T03:00:00+02:00</pubDate>
	  <guid>//late-night-shows</guid>
	  <description><![CDATA[
	     <p>I had the idea for this blog post while I was watching some interviews on YouTube. The videos of the <a href="https://www.youtube.com/user/teamcoco"><em>Conan</em></a> show stood out to me because many of them seem to be focused on sexual topics. To me, it looks like they were following the simple “sex sells” approach. Not that there’s something inherently wrong with this, it just appears that <em>Conan</em> uses it much more than other late-night show channels.</p>

<p><a href="/assets/images/late-night-shows/screenshot.png"><img src="/assets/images/late-night-shows/screenshot.png" alt="Conan Search Results" style="max-width: 600px" /></a></p>

<p>This brought me to my main question. Are <em>Conan</em> videos more focused on sexual content than the ones of other late-night shows? I decided to compare its YouTube channel to the official channels of <a href="https://www.youtube.com/user/JimmyKimmelLive"><em>Jimmy Kimmel Live!</em></a>,  <a href="https://www.youtube.com/user/latenight"><em>The Tonight Show Starring Jimmy Fallon</em></a>, <a href="https://www.youtube.com/channel/UCMtFAi84ehTSYSE9XoHefig"><em>The Late Show with Stephen Colbert</em></a>, and <a href="https://www.youtube.com/user/TheLateLateShow"><em>The Late Late Show with James Corden</em></a>.</p>

<p>The public <a href="https://developers.google.com/youtube/v3/docs/videos/list">YouTube API</a> allowed me to download the information for all available 12,237 videos. To find out whether a video contains sexual content or not, I compared the video’s title and description against a word list (see below). If the title or description contains at least one of the words, the video will be rated as “contains sexual content”. On top of that, I also checked if the video titles contain names of persons to group the videos into three categories: female, male, and neutral. For example, interviews with actresses fall into the female category, whereas, monologs fall into the neutral category.</p>

<p><a href="/assets/images/late-night-shows/barplot.png"><img src="/assets/images/late-night-shows/barplot.png" alt="Late Night Show - Bar Plot" /></a></p>

<p>The graph above shows that <strong>17%</strong> of <em>Conan</em> videos in the female category contain sexual content which is <strong>11%</strong> more than the <em>Late Show with Stephen Colbert</em>, the second place. We also can see that the share of <em>Conan</em> videos containing sexual content is twice as large in the female category than in the male category.  These numbers confirm the hypothesis that the <em>Conan</em> YouTube channel focuses much more on sexual content than other late-night shows. <em>The Tonight Show Starring Jimmy Fallon appears</em> to be the YouTube channel with the cleanest video titles and descriptions.</p>

<p><strong>Bonus:</strong> The results left me wondering if suggestive titles help the channels to gain views. I created the following plot with the <a href="https://cran.cnr.berkeley.edu/web/packages/beanplot/">beanplot</a> R package which shows us that only <em>Conan</em> seems to benefit from sexual video titles or descriptions. If you’re interested in the beanplot, you can find a detailed explanation <a href="https://cran.cnr.berkeley.edu/web/packages/beanplot/vignettes/beanplot.pdf">here</a>.</p>

<p><a href="/assets/images/late-night-shows/beanplot.png"><img src="/assets/images/late-night-shows/beanplot.png" alt="Late Night Show - Bean Plot" style="max-width: 680px" /></a></p>

<pre><code>Word List: boob*, dating*, hooker*, kiss*, love scene*, naked*, naughty*, nude*, nudity*, orgasm*, panties*, penis*, porn*, prostitute*, sex*, slut*, strip*, topless*, whore*
</code></pre>

	  ]]></description>
	</item>

	<item>
	  <title>Chicago pays female employees only 80% of what it pays male employees</title>
	  <link>//pay-gap</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-07-05T03:00:00+02:00</pubDate>
	  <guid>//pay-gap</guid>
	  <description><![CDATA[
	     <p>While I was browsing through the City of <a href="https://data.cityofchicago.org/">Chicago’s Data Catalog</a>, I came across a <a href="https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w">dataset</a> of the city’s 32,000 employees which included their full names, position titles, and annual salaries. I thought that it was a great opportunity to find out whether the gender pay gap was a problem there also. The gender pay gap is the average difference between men’s and women’s earnings, which in the US is somewhere around <a href="http://www.iwpr.org/initiatives/pay-equity-and-discrimination">-21%</a> for women. It is an important number many politicians and activists use as proof for gender inequality.</p>

<p>Before I could compare the average salaries of female and male city employees, I needed to identify their gender – a piece of information which was not included in the official dataset. To do this, I used the R-Package <a href="https://cran.r-project.org/web/packages/gender/index.html"><em>gender</em></a> to predict the gender of a person based on his or her first name. Of course, this method isn’t 100% accurate, but because of the high number of employees, this potential inaccuracy shouldn’t be a problem. After that, I was able to compare the average annual salaries of male and female city employees. It turns out that the City of Chicago isn’t any better than the rest of the nation. It pays its female employees on average, only 80% of what their male colleagues make – which is very close to the national average of 79%.</p>

<p><a href="/assets/images/pay-gap/barchart.png"><img src="/assets/images/pay-gap/barchart.png" alt="Pay Gap Barchart" style="max-width: 500px" /></a></p>

<p>If you think now that there are many other factors besides gender, that determine a person’s salary, and that chart above is completely useless, you are right. It’s obviously not good enough to compare only the average earnings of both genders if they do different kinds of jobs. The criticism of how the gender pay gap is used in political discussions isn’t something new, and it has been proven many times that the gender pay gap isn’t a sufficient proof for gender inequality.</p>

<p>I think one of the problems with the arguments against the gender pay gap is that they often rely on statistical tests. Don’t get me wrong, these tests are the only scientifically correct way to do it; but unfortunately, many people stop listening to you as soon as you start mentioning t-tests and confidence levels. The reason why I find the Chicago dataset so interesting is that it contains the salaries of each employee, which allows us to use it as a real-world example to illustrate the problems with the gender pay gap argument. To do this, I propose a simple scatter plot to display the average male and female salaries per position title.</p>

<p><a href="/assets/images/pay-gap/sketch.png"><img src="/assets/images/pay-gap/sketch.png" alt="Pay Gap Sketch" style="max-width: 300px" /></a></p>

<p>So, each dot represents one job position, like police officer or police sergeant. If a dot (1) is below the 45-degree line, the average salary of men is higher than the average salary of women holding the same position. If a dot (2) is above the 45-degree line, it’s the other way around. In case the average salaries of both genders are equal, the dot (3) sits directly on the line. Based on this idea, I generated the following plot:</p>

<p><a href="/assets/images/pay-gap/scatter_plot.png"><img src="/assets/images/pay-gap/scatter_plot.png" alt="Pay Gap Scatter Plot" style="max-width: 600px" /></a></p>

<p>This plot clearly shows that women are not systematically paid 20% less for doing the same job as the first bar chart might have suggested.  The main reason for the difference is that women are doing different jobs than men do. Therefore, the gender pay gap shouldn’t be used as an argument for the existence of gender inequality but gender differences. I’m not saying that gender discrimination doesn’t exist in the workplace, it’s just that the gender pay gap doesn’t support the claim that women are paid 20% less for doing the same job. Therefore, a more honest way to use this statistic would be in a discussion about how both gender and personal choices affect careers.</p>

<p>In conclusion, it’s true that the gender pay gap exists, and that on average, women make less money than men. However, the claims that it proves gender inequality are false because women are simply doing different kinds of jobs.</p>

<p>If you have questions or concerns, feel free to write me an  <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">email</a>.</p>

<p><small>Photo: “Chicago” by <a href="https://flic.kr/p/62vAsR">Tony Webster</a> is licensed under CC BY 2.0</small></p>

	  ]]></description>
	</item>

	<item>
	  <title>Using Amazon's X-Ray to Visualize Characters' Screen Time</title>
	  <link>//movie-character-screen-time</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-06-22T03:00:00+02:00</pubDate>
	  <guid>//movie-character-screen-time</guid>
	  <description><![CDATA[
	     <p>Today’s blog post is once again about the visualization of movie data. As I already experimented with the IMDb dataset to <a href="http://www.curiousgnu.com/imdb-age-gap">compare the average age</a> of actors and actresses, I wanted to try something a bit different. One thing that I have always found cool is the visualization of movie plots (e.g. <a href="https://xkcd.com/657/">xkcd</a>). The reason why I never attempted to do something like this myself was that I had no idea from where I could get the required data. Of course, there is always the possibility to generate the data manually, but that is usually a tedious task that I try to avoid. Fortunately, I found a much more convenient data source, while I was watching a movie on the <a href="https://www.amazon.com/video">Amazon Video</a> app.</p>

<p><a href="/assets/images/movie-character-screen-time/xray_screenshot.jpg"><img src="/assets/images/movie-character-screen-time/xray_screenshot.jpg" alt="X-Ray Screenshot" style="max-width: 480px" /></a></p>

<p>Its X-Ray feature shows you relevant IMDb information based on which actor is currently in the scene. The app does that based on a single text file which contains the information for when a character appears in a scene. At the end of the post, I will describe how you can extract the file yourself. First, I downloaded the X-Ray file for the latest <a href="https://www.amazon.com/dp/B019G7X9E6">Star Wars movie</a>. Based on this data we can compare the characters by their screen time.</p>

<p><a href="/assets/images/movie-character-screen-time/barplot.png"><img src="/assets/images/movie-character-screen-time/barplot.png" alt="Characters Screen Time by Minutes" style="max-width: 647px" /></a></p>

<p>I noticed that the numbers are not always 100% accurate because some characters are only visible in parts of a scene. However, it should not be a major problem for which we are using them in this post. Next, I used the <a href="https://cran.r-project.org/web/packages/ggplot2/"><em>ggplot2</em></a> package in R to plot the following Gantt chart:</p>

<p><a href="/assets/images/movie-character-screen-time/tp_starwars.png"><img src="/assets/images/movie-character-screen-time/tp_starwars.png" alt="Star Wars The Force Awakens" /></a></p>

<p>We can use the X-Ray data, not only to identify in which scene a character appears but also with whom else. To visualize this information, I used <a href="https://gephi.org/"><em>Gephi</em></a>, an open source tool to plot networks. My assumption is that the longer characters appear on-screen together, the closer their relationship is. The circle size is based on their total screen time.</p>

<p><a href="/assets/images/movie-character-screen-time/network.png"><img src="/assets/images/movie-character-screen-time/network.png" alt="Star Wars - Network Plot" style="max-width: 512px" /></a></p>

<p>I hope these examples show what you can do with Amazon X-Ray data relatively quickly. The best thing of this approach is that it only requires a minimum manual work. So, here are Gantt charts for three other movies I enjoy:
<a href="/assets/images/movie-character-screen-time/tp_big_lebowski.png"><img src="/assets/images/movie-character-screen-time/tp_big_lebowski.png" alt="The Big Lebowski" /></a></p>

<p><a href="/assets/images/movie-character-screen-time/tp_pulp_fiction.png"><img src="/assets/images/movie-character-screen-time/tp_pulp_fiction.png" alt="Pulp Fiction" /></a></p>

<p><a href="/assets/images/movie-character-screen-time/tp_john_wick.png"><img src="/assets/images/movie-character-screen-time/tp_john_wick.png" alt="John Wick" /></a></p>

<h4 id="how-to-get-x-ray-data">How to Get X-Ray Data?</h4>

<p>The X-Ray feature is based on an unencrypted JSON file which can be downloaded with the Chrome browser. Unfortunately, those files are not publicly available (signed CloudFront URL), meaning that you have to start streaming the movie before you can download the file. This also means that you are limited to the content included in your Prime subscription, or you need to rent/buy the movies in which you are interested. Nevertheless, I think it is still an interesting source, especially when you consider the alternatives.</p>

<ol>
  <li>Start Developer Tools: Menu &gt; Tools &gt; Developer Tools</li>
  <li>Start streaming a video &amp; close the player after a few seconds</li>
  <li>Select the following Developer Tools settings:</li>
</ol>

<p><a href="/assets/images/movie-character-screen-time/devtools.png"><img src="/assets/images/movie-character-screen-time/devtools.png" alt="DevTools Settings" /></a></p>

<ol>
  <li>Click on the gray record button to capture the network traffic</li>
  <li>Start streaming the video again</li>
  <li>Now the following file should appear: <em>data.json?Expires=</em></li>
  <li>Right-click on the file &gt; Open Link in New Tab &gt; Save Page As…</li>
</ol>

<p>Then you can use in R the <a href="https://cran.r-project.org/web/packages/jsonlite/index.html"><em>jsonlite</em></a> package to load the JSON file and then do, for example, something like this:</p>

<pre><code>library(jsonlite)
library(ggplot2)

data &lt;- fromJSON("starwars.json", flatten = TRUE)
e &lt;- data$resource$events
e$start &lt;- as.numeric(as.data.frame(e$when)[1,])
e$end &lt;- as.numeric(as.data.frame(e$when)[2,])
ggplot(e, aes(colour=e$character)) + 
  geom_segment(aes(x=e$start, xend=e$end, y=e$character, yend=e$character), size=5)
</code></pre>

	  ]]></description>
	</item>

	<item>
	  <title>Which illicit drugs do Chicagoans take?</title>
	  <link>//chicago-drugs</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-05-27T03:00:00+02:00</pubDate>
	  <guid>//chicago-drugs</guid>
	  <description><![CDATA[
	     <p>In one of my <a href="http://www.curiousgnu.com/cryptomarkets-lsd-sales">previous blog articles</a>, I wrote about how drug dealers use the darknet to sell their products. For this post, I will use police reports to show you more about drug possession in the real world. I chose the city of Chicago because they make all reported incidents of crime available through their <a href="https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2">open data platform</a> which is the basis for the following analysis.</p>

<h5 id="what-are-the-most-common-drugs">What are the most common drugs?</h5>

<p>First, I took all reported incidents of drug possession since 2001 and checked how the numbers have changed over the past 15 years. The following graph shows the number of reported incidents by year and substance. The number of incidents of <em>cannabis</em> possessions peaked at more than 23k in 2010 and then decreased by nearly 55%, landing at 11k in 2015. Reported incidents related to the possession of <em>crack cocaine</em> continuously declined over the years, making heroin the second most common drug since 2010. It should be noted that these numbers only refer to the reported incidents of drug possession and not the actual drug consumption.</p>

<p><a href="/assets/images/chicago-drugs/possession_15_hd.png"><img src="/assets/images/chicago-drugs/possession_01_15.gif" alt="Drug Possession 2001-2015" style="max-width: 100%" /></a></p>

<p>The map on the right shows hot spots in Chicago where many of the incidents took place. This heat map is based on the density of the incidents. In the recent years, we can see a higher concentration of the reports on the West Side.</p>

<h5 id="do-drug-preferences-differ-between-areas">Do drug preferences differ between areas?</h5>

<p>Next, I wanted to find out if some drugs are more popular in certain areas than the others. To do this, I created three new heat maps for the possession of <em>cocaine</em>, <em>heroin</em>, and <em>cannabis</em>. As we can see below, there seems to be a difference between the three substances:</p>

<p><a href="/assets/images/chicago-drugs/map_grid.jpg"><img src="/assets/images/chicago-drugs/map_grid.jpg" alt="Possession by Community Areas" /></a></p>

<p>To find an explanation for the local differences, I downloaded <a href="https://datahub.cmap.illinois.gov/dataset/community-data-snapshots-raw-data-2015/resource/8c4e096e-c90c-4bef-9cf1-9028d094296e">census data</a> on a community area level. We can use this data to explore how the community areas differ from each other in factors like education, income, race, or unemployment. If we plot this data in a map format and compare them to the previous heat maps, it shows that there could be a connection between them and the possession of certain drugs.</p>

<p>Judging by the looks of graphs is of course, not an appropriate method, which is why I also used a spatial regression to test how education, income, race, and unemployment relates to the reported possession of cocaine, heroin, and cannabis. The depended variables are the percentage of reported incidents based on the total population of the community area in which they occurred.</p>

<p>The results below show that reported cannabis possession is lower in community areas with a higher median income and education. For heroin, we see similar results with the exception that median income is not a significant factor but median age is. For cocaine, the only two significant variables are the relative shares of the Black and Hispanic population. Apparently more incidents of cocaine possession happen in areas with bigger Black and Hispanic populations.</p>

<p><a href="/assets/images/chicago-drugs/regression_table.png"><img src="/assets/images/chicago-drugs/regression_table.png" alt="Regression Results" style="max-width: 640px" /></a></p>

<p>If you have any suggestion or tips for future articles, please feel free to contact me by <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">email</a> or <a href="https://www.reddit.com/user/CuriousGnu/">Reddit message</a>.</p>

	  ]]></description>
	</item>

	<item>
	  <title>78% of Reddit Threads With 1,000+ Comments Mention Nazis</title>
	  <link>//reddit-godwin</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-05-04T03:00:00+02:00</pubDate>
	  <guid>//reddit-godwin</guid>
	  <description><![CDATA[
	     <p>Let me start this post by noting that I will not attempt to test <a href="https://en.wikipedia.org/wiki/Godwin%27s_law">Godwin’s Law</a>, which states that:</p>

<pre><code>As an online discussion grows longer, the probability of a comparison involving Nazis or Hitler approaches 1.
</code></pre>

<p>In this post, I’ll only try to find out how many Reddit comments mention <em>Nazis</em> or <em>Hitler</em> and ignore the context in which they are made. The data source for this analysis is the <a href="https://bigquery.cloud.google.com/table/fh-bigquery:reddit_comments.2016_03">Reddit dataset</a> which is publicly available on Google BigQuery. The following graph is based on <strong>4.6 million</strong> comments and shows the share of comments mentioning <em>Nazis</em> or <em>Hitler</em> by subreddit.</p>

<p><a href="/assets/images/rd-godwin/subrd.png"><img src="/assets/images/rd-godwin/subrd.png" alt="Hitler Comments by Subreddits" /></a></p>

<p>Then I excluded history subreddits and looked at the probability that a Reddit thread mentions <em>Nazis</em> or <em>Hitler</em> at least once. Unsuprisigly, the probability of a Nazi refrence increases as the threads get bigger. Nevertheless, I didn’t expect that the probability would be <strong>over 70%</strong> for a thread with more than 1,000 comments.</p>

<p><a href="/assets/images/rd-godwin/pbrd.png"><img src="/assets/images/rd-godwin/pbrd.png" alt="Hitler References" style="max-width:780px" /></a></p>

<p>The next step would be to implement sophisticated text mining techniques to identify comments which use Nazi analogies in a way as described by Godwin. Unfortunately due to time constraints and the complexity of this problem, I was not able to try for this blog post.</p>

	  ]]></description>
	</item>

	<item>
	  <title>How The World Sees Hillary Clinton & Donald Trump</title>
	  <link>//how-the-world-sees-clinton-trump</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-04-27T19:14:00+02:00</pubDate>
	  <guid>//how-the-world-sees-clinton-trump</guid>
	  <description><![CDATA[
	     <p>For this week’s blog post, I will try to find out how the international news media writes about Hillary Clinton and Donald Trump; the presidential front-runners of both parties. The plan is to check on several international news sources to derive positive and negative things regarding Hillary Clinton or Donald Trump. Doing this will give us an idea of how the news media in other countries, writes and talks about the two candidates.</p>

<p>Fortunately, most of the hard work was already done by the <a href="http://gdeltproject.org/">GDELT Project</a>, which monitors news sites from all around the world and makes its work freely available for everyone. They even automatically determine how positive or negative news articles are using sentiment analysis. Based on the <a href="http://gdeltproject.org/data.html">GDELT dataset</a>, I created a map for each candidate which shows how the average tone of the texts compares to American news (Clinton: -1.15; Trump: -1.40). The results are based on a total of over <strong>550,000 articles</strong> published after July 2015 of which 65.3% mentioned <em>Donald Trump</em> at least twice, and 46.1% mentioned <em>Hillary Clinton</em> at least twice.</p>

<div class="emb-iframe">
  <iframe height="612" width="980" frameborder="0" src="https://curiousgnu.cartodb.com/viz/5497e1dc-0991-11e6-87dd-0e5db1731f59/embed_map" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>
</div>
<div class="emb-iframe">
  <iframe height="612" width="980" frameborder="0" src="https://curiousgnu.cartodb.com/viz/676de180-0991-11e6-9940-0e674067d321/embed_map" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>
</div>

<p>Compared to the Republican front-runner Donald Trump, international journalists seem to view Hillary Clinton much more positively. Looking at the maps above, we can see that news articles from countries like <em>Mexico</em>, <em>India</em>, or <em>China</em> are clearly more favorable towards Clinton than Trump. One exception is the Russian media which reports 19% more positively about Trump than its American counterpart. I don’t want to get political, but I think the results for some countries aren’t much of a surprise.</p>

<h4 id="technical-background">Technical Background</h4>

<p>The process of doing this analysis is fairly straightforward and does not require anything except a browser and a Google account. First, I used the <a href="http://gdeltproject.org/">GDELT database</a>, publicly available on <a href="https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.gkg">Google BigQuery</a>, to extract the raw data needed to create both maps. I wrote the following SQL query to do this:</p>

<pre class="sql"><code>SELECT	a.country
	,AVG(CASE WHEN a.trump = 1 
		THEN a.tone ELSE NULL END) trump_tone
	,AVG(CASE WHEN a.hillary = 1
		THEN a.tone ELSE NULL END) hillary_tone
FROM (SELECT 
  cc.CountryHumanName country
  ,CASE WHEN 
  	LOWER(gkg.AllNames) LIKE '%donald%trump%donald%trump%'
  	THEN 1 ELSE 0 END trump
  ,CASE WHEN
  	LOWER(gkg.AllNames) LIKE '%hillary%clinton%hillary%clinton%'
  	THEN 1 ELSE 0 END hillary
  ,FIRST(SPLIT(gkg.V2Tone, ',')) tone
FROM [gdelt-bq:gdeltv2.gkg] gkg
INNER JOIN [gdelt-bq:gdeltv2.domainsbycountry_alllangs_april2015] cc
  ON cc.Domain = gkg.SourceCommonName
WHERE (
  	LOWER(gkg.AllNames) LIKE '%donald%trump%donald%trump%'
  	OR LOWER(gkg.AllNames) LIKE '%hillary%clinton%hillary%clinton%'
  ) AND gkg.DATE &gt;= 20150801000000
) a
GROUP BY a.country
HAVING	SUM(a.trump) &gt;= 100
	AND SUM(a.hillary) &gt;= 100
</code></pre>

<p>In the second step, I exported the results of the query as a CSV file and uploaded it to <a href="https://cartodb.com/">CartoDB</a>, a free web service where you can create maps based on location-based data. From there on you can follow their documentation and have your maps ready in no time.</p>

<p>From my experience, <a href="https://cartodb.com/">CartoDB</a> is a great tool if you want to create interactive and highly customizable maps. If you only need a basic set of features, you ought to try out <a href="https://www.google.com/sheets/about/">Google Sheets</a>. <a href="http://www.tableau.com/">Tableau</a> is another good alternative that I frequently use, which is also available in the free version <a href="https://public.tableau.com/s/">Tableau Public</a>. I didn’t use Tableau in this project because CartoDB offers much better embedding options for blogs or websites.</p>

<p>If you have any questions about this blog post, feel free to contact me by <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">email</a> or write me a PM on Reddit.</p>

<p> </p>

<p><small>Photos by <a href="https://www.flickr.com/photos/gageskidmore/">Gage Skidmore</a> is licensed under CC BY-SA 2.0</small></p>

	  ]]></description>
	</item>

	<item>
	  <title>Redditors who commented in /r/X also commented in /r/Y</title>
	  <link>//reddit-comments</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-04-20T14:14:00+02:00</pubDate>
	  <guid>//reddit-comments</guid>
	  <description><![CDATA[
	     <p>This blog article is about <a href="http://www.reddit.com">reddit.com</a>, a website where people can post links to interesting websites and discuss a wide variety of different topics. According to <a href="http://www.alexa.com/topsites/countries/US">Alexa</a>, a company who analyzes web traffic, Reddit is the ninth most popular site in the United States. Reddit has thousands of different subcategories, called subreddits, which are usually moderated by volunteers. There are subreddits for nearly every topic you can imagine; for example, on <a href="http://www.reddit.com/r/movies">/r/movies</a> people can discuss the latest blockbuster whereas the users over at <a href="http://www.reddit.com/r/sloths">/r/sloths</a> are passionately committed to collecting cute pictures of sloths.</p>

<p>But Reddit can also be fascinating to people who are interested in data research because the user generated data is easily accessible via the official API and through <a href="https://bigquery.cloud.google.com/table/fh-bigquery:reddit_comments.2016_01">Google BigQuery</a> where you can find an SQL database which you can use for little to no cost. For this article, I decided to start with something simple. My goal is to find out how the 50 most popular subreddits are related to each other. The idea behind it is that users usually write comments in subreddits which are close to their personal interests, meaning that a user who is active in the <a href="http://www.reddit.com/r/StarWars">/r/StarWars</a> subreddit is probably also active in the <a href="http://www.reddit.com/r/firefly">/r/firefly</a> subreddit because both categories fit his or her interest in science fiction.</p>

<p><a href="/assets/images/rd-comments/rd_comments_net_hd.png"><img src="/assets/images/rd-comments/rd_comments_net_hd.png" alt="Subreddit Network" style="max-height:640px; max-width:640px" /></a></p>

<p>Based on this assumption, my approach was to look at all 1.2 million unique users who posted a comment in at least one of the top 50 subreddits during January 2016. To calculate the strength of the relationship between the subreddits, I used multiple logistic regression models which for example can tell us how much the probability of a Redditor posting a comment in <a href="http://www.reddit.com/r/StarWars">/r/StarWars</a> increases if he or she also posted a comment in <a href="http://www.reddit.com/r/firefly">/r/firefly</a>. The bigger this number is, the more closely related those subreddits are to each other. The network graph above is a visualization of these results. A bigger dot stands for a larger number of connections to its neighbors.</p>

<p>Looking at the graph, we can identify four major groups of subreddits:</p>

<ol>
  <li><strong>News &amp; Science</strong>: <a href="http://www.reddit.com/r/worldnews">/r/worldnews</a>, <a href="http://www.reddit.com/r/science">/r/science</a>, <a href="http://www.reddit.com/r/space">/r/space</a>, <a href="http://www.reddit.com/r/futurology">/r/futurology</a>, …</li>
  <li><strong>Entertainment</strong>: <a href="http://www.reddit.com/r/movies">/r/movies</a>, <a href="http://www.reddit.com/r/television">/r/television</a>, <a href="http://www.reddit.com/r/music">/r/music</a>, <a href="http://www.reddit.com/r/books">/r/books</a>, …</li>
  <li><strong>Visual Content</strong>: <a href="http://www.reddit.com/r/funny">/r/funny</a>, <a href="http://www.reddit.com/r/pics">/r/pics</a>, <a href="http://www.reddit.com/r/aww">/r/aww</a>, <a href="http://www.reddit.com/r/creepy">/r/creepy</a>, …</li>
  <li><strong>Textual Content</strong>: <a href="http://www.reddit.com/r/showerthought">/r/showerthought</a>, <a href="http://www.reddit.com/r/askreddit">/r/askreddit</a>, <a href="http://www.reddit.com/r/tifu">/r/tifu</a>, <a href="http://www.reddit.com/r/lifeprotips">/r/lifeprotips</a>, …</li>
</ol>

<p>The subreddit <a href="http://www.reddit.com/r/todayilearned">/r/todayilearned</a> doesn’t belong to any particular group because it’s somewhat popular among all users. This analysis doesn’t go into great detail, but I think it’s nevertheless interesting to see that the groups of subreddit seem to make sense and can be interpreted. For example, it doesn’t sound wrong that users who enjoy commenting on topics about space are also interested in science.</p>

<p>Additionally, I also made a table from the same data. The software programs I used to create both graphs are <a href="https://gephi.org/">Gephi</a> and <a href="https://public.tableau.com/s/">Tableau</a> respectively. A blue square stands for a positive correlation coefficient whereas a red square represents the opposite.  You can open the full table by clicking on the graph below:</p>

<p><a href="https://public.tableau.com/profile/curious.gnu#!/vizhome/RedditComments-LogitRegressioncuriousgnu_com/Sheet1"><img src="/assets/images/rd-comments/rd_table.png" alt="Subreddit Table" /></a></p>

<p>Admittedly, these aren’t exactly groundbreaking results, but it was real fun to try out some statistical methods on this huge amount of data. I’m currently testing how I can use this data source for an article about text analysis.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Penny Auctions - How to sell a $180 tablet for $7,264</title>
	  <link>//penny-auctions</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-04-04T20:00:00+02:00</pubDate>
	  <guid>//penny-auctions</guid>
	  <description><![CDATA[
	     <p>Unless you use an ad blocker, you probably notice ads for penny auction sites from time to time. They usually advertise with sketchy messages like <em>“iPhone sold for $14.21.”</em> They can sell iPhones such low prices because of their unusual auction system where each bid increases the auction price by only one cent. This works because unlike eBay each bid costs money (e.g., $0.40) no matter if you end up winning the auction or not. You have to be the highest bidder when the clock runs out to win the auction. The problem is that each bid adds ten seconds to the countdown which gives other bidders the time to counter your bid.</p>

<p><img src="/assets/images/penny-auctions/mockup_paad.jpg" alt="Penny Auction" /></p>

<p>Penny auction sites are not something new and have been criticized a lot, which makes you wonder how they are still in business. Even though there are many news articles about online penny auctions, I did not find any numbers or statistics which would support the criticism. So I started to collect information on my own, to get a better understanding how these auctions work in reality. What I found exceeded all my expectations.</p>

<p>On <a href="https://en.wikipedia.org/wiki/Beezid">beezid.com</a>, one of the bigger penny auction sites, a single $180 tablet generated 18,160 bids, worth of over <strong>$7,200</strong>, from 56 users. Shockingly nearly half of those bids came from just one person who lost approximately lost <strong>$3,500</strong> in just two hours (see graph below). The winner of this auction only spent 80 cents on his or her two bids. In the second half of this blog post, I will outline the data collection process. To protect the users’ privacy, I replaced the real usernames with chemical elements.</p>

<p><a href="/assets/images/penny-auctions/money_spent_hd.png"><img src="/assets/images/penny-auctions/money_spent.png" alt="Money Spent on Bids" /></a></p>

<h4 id="why-are-penny-auctions-even-popular">Why are penny auctions even popular?</h4>
<p>The big ‘achievement’ of penny auction sites is that they successfully turned an unappealing type of an all-pay auction into an online game which makes people believe that they could make a profit.  The way beezid.com does this is actually quite clever. First, they give their users many different options how they can make a bid. Users can, for example, use automatic bidding bots, take advantage of price limits above which the auction price will not rise, and purchase a wide variety of other supposedly useful add-ons. Second, they try to hide all information that could reveal how many people are participating in the auction and how much they already spent in total.</p>

<p>One way they do this is by their default 10% price limit, which means the auction price will never rise above 10% of the retail price, no matter how many people bid on it. Another strange rule is that bids do not always increase the auction price by one cent but can also lower it by some amount. These modifications of the system make the auction price more or less meaningless because you can no longer assume that, for example, a price of $1.10 is a result of 110 unique bids. Many articles about penny auctions (e.g., <a href="http://www.consumerreports.org/cro/2011/12/with-penny-auctions-you-can-spend-a-bundle-but-still-leave-empty-handed/index.htm">consumerreports.org</a>) do not account for these rules and falsely assume a fixed price increase. The graph below shows the development of the auction price of the $180 tablet over time. If we assume, that each bid would have increased the price by always one cent, the final auction price would have been <strong>$181.60</strong>.</p>

<p><a href="/assets/images/penny-auctions/auction_price_hd.png"><img src="/assets/images/penny-auctions/auction_price.png" alt="Auction Price" /></a></p>

<p>This lack of transparency combined with the many different bidding options creates a system which gives users the illusion that they could make a profit with the right strategies.</p>

<h4 id="how-to-monitor-penny-auctions">How to monitor penny auctions?</h4>
<p>Despite the site’s efforts to keep their users in the dark, it is possible to archive the complete bidding history of an auction, if you monitor it from its start. To collect the data for this blog post, I wrote a simple <a href="https://gist.github.com/CuriousGnu/cf558e8ca8cbbd491619a9e1940682c3">script</a> in Python which automatically saves the all bidding information of a <a href="https://en.wikipedia.org/wiki/Beezid">beezid.com</a> auction. If you want to try it out yourself, you only have to change the auction id and update the request header. You can easily get this information with the Chrome DevTools. In case, you have a slow or unstable internet connection I highly recommend running the script on a server (e.g., <a href="https://www.digitalocean.com/pricing/">Digital Ocean</a>). It should be noted that the script behaves like a regular browser and does not bypass any server-side security or content protection mechanisms.</p>

<h4 id="arent-penny-auctions-unregulated-gambling">Aren’t penny auctions unregulated gambling?</h4>
<p>One of the most important parts of the business models of penny auction sites is that what they are doing is not considered gambling. I am not a lawyer, so I will not attempt to question the legality of their operations. Their central argument is that penny auctions require skill and are therefore exempt from the <a href="https://en.wikipedia.org/wiki/Unlawful_Internet_Gambling_Enforcement_Act_of_2006">Unlawful Internet Gambling Enforcement Act</a>, which is the same legal loophole daily fantasy sports sites like <a href="https://en.wikipedia.org/wiki/FanDuel">FanDuel</a> or <a href="https://en.wikipedia.org/wiki/DraftKings">DraftKings</a> use. Personally, I cannot see how any skill could increase your chances of winning an auction. The data clearly shows that you are bidding against an unknown number of users who sometimes act extremely irrational. Even if you had a comprehensive database of previous auctions, you probably would not be able to predict how far a specific user will go. If someone has already spent over $3,000 on a $180 tablet, what could stop them aside from his or her credit card limit? It would be really interesting to hear an official explanation of how skill is even a factor in this game.</p>

<p>If you have any questions about this blog post, feel free to contact me by <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">email</a>.</p>

	  ]]></description>
	</item>

	<item>
	  <title>How positive are your tweets?</title>
	  <link>//tweetanalyzer</link>
	  <author>CuriousGnu</author>
	  <pubDate>2016-03-16T22:42:00+01:00</pubDate>
	  <guid>//tweetanalyzer</guid>
	  <description><![CDATA[
	     <p>In this blog post, I would like to present you <a href="https://tweetanalyzer.net">tweetanalyzer.net</a>, a small project of mine, where you can do a sentiment analysis of your tweets or the ones of any other Twitter user. The goal was to create a fun website which uses text analysis to determine how positive someone’s tweets are.</p>

<p><a href="https://tweetanalyzer.net"><img src="/assets/images/tweetanalyzer/screen.png" alt="TweetAnalyzer.net" /></a></p>

<p>After you signed in with your Twitter account, you can type in any username and the website will automatically download the latest 200-300 tweets and calculate a positivity and vulgarity score for each of them. The method used to do this is very simple. The backend uses the AFINN word list from <a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010">Finn Årup Nielsen</a>, which contains nearly 2,500 words rated for their positivity from -5 (negative) to +5 (positive). After removing stop words, hashtags, and URLs the script looks up every word in this list and calculates the sum for each tweet. If this sum is over zero, the tweet will be marked as positive if it’s under zero as negative. The overall positivity score for a user is then calculated as follows:</p>

<p><img src="/assets/images/tweetanalyzer/positivity_score.gif" alt="PSF" /></p>

<p>Admintingly this approach has its weakness and is not as sophisticated as many other methods classification technique out there. For example, it can not understand the context of a tweet and how a specific word (e.g., <em>sick</em>) is used. I experimented more complex Python libraries for text analysis, but unfortunately they did not run well on the Google App Engine platform if you plan to analyse thousands of tweets but only have a limited budget. I am sure that it can be done without a problem but since I never used it before and did not want to spend too much time on it, I decided to use the simple solution which I believe is still sufficient for such a task.</p>

<p>To determine how vulgar a tweet is, the software uses a similar word list based method. If a tweet contains a word which is in this list, it will be marked as <em>vulgar</em>. The lack of content-awareness will, of course, lead to some mistakes. For example, news articles about <em>sex trafficking</em> or <em>rape</em> will be falsely classified as <em>vulgar</em>. So please do not take the results too seriously and rather tweet something positive about it! Feel free to <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#099;&#117;&#114;&#105;&#111;&#117;&#115;&#103;&#110;&#117;&#046;&#099;&#111;&#109;">contact me</a> if you suggestions or questions.</p>

<p>You can find the project here: <a href="https://tweetanalyzer.net">https://tweetanalyzer.net</a></p>

	  ]]></description>
	</item>


</channel>
</rss>
